# 2. Solución de ecuaciones no lineales

Dado $f:\mathbb{R}\to\mathbb{R}$ no lineal, se desea encontrar una solución $r$ de la ecuación

$$
f(x)=0
$$

**Idea**: comenzando con algún $x_0\in\mathbb{R}$, generar una sucesión $\{x_k\}$ a través de un algoritmo numérico iterativo, y se espera que tal sucesión converja a $r$ donde $f(r)=0$.

---

## Método de bisección

Se basa fuertemente en el teorema del valor intermedio: si $f$ es continua en $[a,b]$ y si $f(a)f(b)<0$, entonces $f$ debe tener una raíz en $(a,b)$.

---

### Idea del método

Si $f(a)f(b)<0$, se calcula $c=\frac{a+b}{2}$ y $f(c)$. Sean $x_0=c$ una aproximación a la raíz $r$  de $f$ y 

$$
|e_0|=|x_0-r|\leq\frac{b-a}{2}
$$

error de aproximación inicial. Se tienen 3 posibilidades:

1. si $f(a)f(c)<0$, hay una raíz en $[a,c]$. Reasignamos $b\leftarrow c$ y se repite el procedimiento en el nuevo intervalo $[a,b]$.

2. si $f(a)f(c)>0$, hay una raíz en $[c,b]$. Reasignamos $a\leftarrow c$ y se repite el procedimiento en el nuevo intervalo $[a,b]$

3. si $f(a)f(c)=0$, entonces $f(c)=0$ y $x_0=c$ es la raíz buscada.

---

**Observación**

La reasignación

$$
c\leftarrow \frac{a+b}{2}
$$

puede causar un *overflow* si $a$ y $b$ son números muy grandes, o una perdida de precisión si ambos son muy grandes y muy parecidos. En su lugar, es mejor usar:

$$
c\leftarrow a+\frac{(b-a)}{2}
$$

---

### Teorema de convergencia del método de bisección

Si $[a_0,b_0],[a_1,b_1],…,[a_,b_n]$ denotan los sucesivos intervalos en el método de bisección, entonces existen los límites: $\displaystyle\lim_{n\to∞}a_n$ y $\displaystyle\lim_{n\to∞}b_n$ son iguales y representan una raíz de $f$.

Si
$
c_n=\frac{1}{2}(a_n+b_n)
$
y 
$
r = \lim_{n\to ∞}c_n
$ entonces

$$
|r-c_n|\leq\frac{1}{2^{n+1}}(b_0-a_0)
$$

---

## Método de Newton

Comenzando con una aproximación $x_0$ de $r$, la iteración del método de Newton consiste en calcular

$$
x_{n+1}=x_n-\frac{f(x_n)}{f'(x_n)},\qquad n\geq 0
$$

---
El siguiente resultado muestra que bajo ciertas hipótesis la sucesión generada por el método de Newton converge **local** y **cuadráticamente**.

---

**Teorema 1**

Si $f''$ es continua un entorno de una raíz $r$ de $f$ y si $f'(r)\neq0$ entonces existe $\delta >0$ tal que si el punto inicial $x_0$ satisface $|r-x_0|\leq\delta$ luego todos los puntos de la sucesión $\{x_n\}$ generados por el algoritmo de Newton satisfacen que $|r-x_n|\leq\delta$ para todo $n$, la sucesión $\{x_n\}$ converge a $r$ y la convergencia es cuadrática.

Es decir, existen una constante $c=c(\delta)$ y un natural $N$ tal que

$$
|r-x_{n+1}|\leq c|r-x_n|^2\qquad n\geq N
$$

---

**Teorema 2**

Si $f''$ es continua en  $\mathbb{R}$, $f$ es creciente y convexa en $\mathbb{R}$ y tiene una raíz, entonces esa raíz es única y la iteración de Newton convergerá a esa raíz independientemente del punto inicial $x_0$.

---

## Método de la secante

La idea consiste en reemplazar $f'(x_n)$ en iteración de Newton por una aproximación:

$$
f'(x_n)\approx \frac{f(x_n)-f(x_{n-1})}{x_n-x_{n-1}}
$$

Así, la iteración del método secante consiste en:

$$
x_{n+1}=x_n-f(x_n)\frac{x_n-x_{n-1}}{f(x_n)-f(x_{n-1})}\qquad n\geq1
$$

---

Es posible probar que:

$$
e_{n+1}\approx ce_n^{\alpha}=(ce_n^{\alpha-1})e_n
$$

donde $\alpha=(1+\sqrt{5})/2$. Como $1<\alpha<2$ se dice que el método de la secante tiene **convergencia superlineal**. Esto dice que **dos iteraciones de método de la secante** es mejor que **una iteración del método de Newton**.

---

## Iteración de punto fijo

**Definición**

Un punto fijo de una función $\text{g}$ es un número $p$, en el dominio de $\text{g}$ tal que $\text{g}(p)=p$.

---

Si $\text{g}$ tiene un punto fijo en $p$, esto es $\text{g}(p)=p$, entonces $f(x)=x-\text{g}(x)$ tiene una raíz en $p$.

---

**Teorema 1**

1. Si $\text{g}\in C[a,b]$ y $\text{g}(x)\in[a,b]$ para todo $x\in[a,b]$ entonces existe $p\in[a,b]$ tal que $\text{g}(p)=p$. **(Existencia)**

2. Si además existe $\text{g}'(x)$ para todo $x\in(a,b)$ y existe una constante positiva $k<1$ tal que $|\text{g}'(x)|<1$ para todo $x\in(a,b)$, entonces el punto fijo en $(a,b)$ es único. **(Unicidad)**

---

### Idea del algoritmo de punto fijo

Para calcular aproximadamente el punto fijo de una función $\text{g}$ primero se inicia con un aproximación  $p_0$ y calculando 

$$
p_n=\text{g}(p_{n-1})
$$

para $n\geq 1$, se obtiene una sucesión de aproximaciones $\{p_n\}$. Si la función $\text{g}$ es continua y la sucesión converge entonces lo hace a un punto fijo $p$ de $\text{g}$ pues

$$
p=\lim_{n\to\infty}p_n=\lim_{n\to\infty}\text{g}(p_{n-1})=\text{g}\left(\lim_{n\to\infty}p_{n-1}\right)=\text{g}(p)
$$

---

**Teorema 2**

Sea $\text{g}$ que cumple con los puntos $1$ y $2$ del Teorema 1, entonces para cualquier $p_0\in[a,b]$, la sucesión $p_n=\text{g}(p_{n-1})$, para $n\geq1$, coverge al único punto fijo $p$ en $(a,b)$.

---

**Corolario 1**

Si $\text{g}$ es una función que satisface las hipótesis del  teorema anterior, se tienen las siguientes cotas de error

$$
\begin{align*}
|p_n-p|&\leq k^n\max\{p_0-a,b-p_0\}\\
|p_n-p|&\leq \frac{k^n}{1-k}|p_1-p_0|\qquad\text{para todo }n\geq1
\end{align*}
$$

---

